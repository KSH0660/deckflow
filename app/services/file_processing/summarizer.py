"""íŒŒì¼ ë‚´ìš© ìš”ì•½ì„ ìœ„í•œ ì²­í‚¹ ê¸°ë°˜ ëª¨ë“ˆ"""

import asyncio

from app.adapter.llm.langchain_client import LangchainLLM
from app.core.config import settings
from app.logging import get_logger

from .models import ChunkSummary

logger = get_logger(__name__)


class FileSummarizer:
    """ì²­í‚¹ ê¸°ë°˜ íŒŒì¼ ë‚´ìš© ìš”ì•½ í´ë˜ìŠ¤"""

    # ìš”ì•½ì´ í•„ìš”í•œ ìµœì†Œ í…ìŠ¤íŠ¸ ê¸¸ì´ (8KB)
    MIN_TEXT_LENGTH_FOR_SUMMARY = 8000

    # ì²­í¬ í¬ê¸° (4KB)
    CHUNK_SIZE = 4000

    # ì²­í¬ ê°„ ì˜¤ë²„ë© (200ì)
    CHUNK_OVERLAP = 200

    def __init__(self):
        """ìš”ì•½ìš© LLM ì´ˆê¸°í™”"""
        self.llm = LangchainLLM(model=settings.summarization_model)
        logger.info(
            "ğŸ§  [FILE_SUMMARIZER] ì²­í‚¹ ê¸°ë°˜ íŒŒì¼ ìš”ì•½ê¸° ì´ˆê¸°í™” ì™„ë£Œ",
            model=settings.summarization_model,
            min_length_for_summary=self.MIN_TEXT_LENGTH_FOR_SUMMARY,
            chunk_size=self.CHUNK_SIZE,
            chunk_overlap=self.CHUNK_OVERLAP,
        )

    def split_into_chunks(self, text: str) -> list[str]:
        """í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ë¬¸ì¥ ê²½ê³„ ê³ ë ¤)"""

        if len(text) <= self.CHUNK_SIZE:
            return [text]

        chunks = []
        start = 0

        while start < len(text):
            end = start + self.CHUNK_SIZE

            # ë§ˆì§€ë§‰ ì²­í¬ì¸ ê²½ìš°
            if end >= len(text):
                chunks.append(text[start:])
                break

            # ë¬¸ì¥ ê²½ê³„ì—ì„œ ìë¥´ê¸° ì‹œë„
            chunk_text = text[start:end]

            # ë§ˆì§€ë§‰ ë¬¸ì¥ ë ì°¾ê¸° (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ)
            last_sentence_end = max(
                chunk_text.rfind("."),
                chunk_text.rfind("!"),
                chunk_text.rfind("?"),
                chunk_text.rfind("\n"),
            )

            # ì ì ˆí•œ ë¬¸ì¥ ëì„ ì°¾ì•˜ë‹¤ë©´ ê±°ê¸°ì„œ ìë¥´ê¸°
            if last_sentence_end > self.CHUNK_SIZE * 0.7:  # ë„ˆë¬´ ì§§ì§€ ì•Šë‹¤ë©´
                actual_end = start + last_sentence_end + 1
                chunks.append(text[start:actual_end])
                start = actual_end - self.CHUNK_OVERLAP
            else:
                # ë¬¸ì¥ ëì„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ ê·¸ëƒ¥ ìë¥´ê¸°
                chunks.append(text[start:end])
                start = end - self.CHUNK_OVERLAP

        logger.debug(
            "ğŸ“„ [FILE_SUMMARIZER] í…ìŠ¤íŠ¸ ì²­í‚¹ ì™„ë£Œ",
            total_length=len(text),
            chunk_count=len(chunks),
            avg_chunk_size=sum(len(chunk) for chunk in chunks) // len(chunks),
        )

        return chunks

    async def summarize_chunk(self, chunk: str, chunk_index: int, filename: str) -> str:
        """ë‹¨ì¼ ì²­í¬ë¥¼ ìš”ì•½"""

        prompt = f"""Summarize the following text chunk in a concise manner suitable for presentation creation. Focus on key information and important details. Keep the summary around 500 characters.

Filename: {filename}
Chunk: {chunk_index + 1}

Content:
{chunk}"""

        try:
            result: ChunkSummary = await self.llm.generate_structured(
                prompt, schema=ChunkSummary
            )

            logger.debug(
                "âœ… [FILE_SUMMARIZER] ì²­í¬ ìš”ì•½ ì™„ë£Œ",
                filename=filename,
                chunk_index=chunk_index,
                original_length=len(chunk),
                summary_length=len(result.summary),
            )

            return result.summary.strip()

        except Exception as e:
            logger.warning(
                "âš ï¸ [FILE_SUMMARIZER] ì²­í¬ ìš”ì•½ ì‹¤íŒ¨ - ì›ë³¸ ì¼ë¶€ ë°˜í™˜",
                filename=filename,
                chunk_index=chunk_index,
                error=str(e),
            )
            # ìš”ì•½ ì‹¤íŒ¨ì‹œ ì›ë³¸ì˜ ì¼ë¶€ë§Œ ë°˜í™˜
            return chunk[:500] + "..." if len(chunk) > 500 else chunk

    def merge_summaries(self, summaries: list[str], filename: str) -> str:
        """ì—¬ëŸ¬ ì²­í¬ ìš”ì•½ì„ í•˜ë‚˜ë¡œ ë³‘í•©"""

        merged = f"""íŒŒì¼ '{filename}' ìš”ì•½:

{chr(10).join(f"â€¢ {summary}" for summary in summaries if summary.strip())}"""

        logger.info(
            "ğŸ”— [FILE_SUMMARIZER] ì²­í¬ ìš”ì•½ ë³‘í•© ì™„ë£Œ",
            filename=filename,
            chunk_count=len(summaries),
            merged_length=len(merged),
        )

        return merged

    async def should_summarize(self, text: str) -> bool:
        """í…ìŠ¤íŠ¸ê°€ ìš”ì•½ì´ í•„ìš”í•œ ê¸¸ì´ì¸ì§€ í™•ì¸"""
        return len(text) > self.MIN_TEXT_LENGTH_FOR_SUMMARY

    async def summarize_for_presentation(self, text: str, filename: str) -> str:
        """ì²­í‚¹ ê¸°ë°˜ìœ¼ë¡œ íŒŒì¼ ë‚´ìš©ì„ í”„ë ˆì  í…Œì´ì…˜ì— ì í•©í•˜ê²Œ ìš”ì•½"""

        if not await self.should_summarize(text):
            logger.info(
                "ğŸ“„ [FILE_SUMMARIZER] ìš”ì•½ ë¶ˆí•„ìš” - ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜",
                filename=filename,
                text_length=len(text),
            )
            return text

        logger.info(
            "ğŸ“„ [FILE_SUMMARIZER] ì²­í‚¹ ê¸°ë°˜ íŒŒì¼ ìš”ì•½ ì‹œì‘",
            filename=filename,
            original_length=len(text),
        )

        try:
            # 1. ì²­í‚¹
            chunks = self.split_into_chunks(text)

            # 2. ë³‘ë ¬ ìš”ì•½
            logger.info(
                "ğŸ”„ [FILE_SUMMARIZER] ì²­í¬ ë³‘ë ¬ ìš”ì•½ ì‹œì‘",
                filename=filename,
                chunk_count=len(chunks),
            )

            chunk_summaries = await asyncio.gather(
                *[
                    self.summarize_chunk(chunk, i, filename)
                    for i, chunk in enumerate(chunks)
                ]
            )

            # 3. ë³‘í•©
            final_summary = self.merge_summaries(chunk_summaries, filename)

            logger.info(
                "âœ… [FILE_SUMMARIZER] ì²­í‚¹ ê¸°ë°˜ ìš”ì•½ ì™„ë£Œ",
                filename=filename,
                original_length=len(text),
                final_summary_length=len(final_summary),
                chunk_count=len(chunks),
                compression_ratio=round(len(final_summary) / len(text), 2),
            )

            return final_summary

        except Exception as e:
            logger.error(
                "âŒ [FILE_SUMMARIZER] ì²­í‚¹ ìš”ì•½ ì‹¤íŒ¨ - í…ìŠ¤íŠ¸ ì ˆë‹¨ìœ¼ë¡œ í´ë°±",
                filename=filename,
                error=str(e),
            )
            # ìš”ì•½ ì‹¤íŒ¨ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ì˜ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
            fallback_length = 6000
            return (
                text[:fallback_length] + "..." if len(text) > fallback_length else text
            )


# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_summarizer_instance = None


async def get_file_summarizer() -> FileSummarizer:
    """FileSummarizer ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _summarizer_instance
    if _summarizer_instance is None:
        _summarizer_instance = FileSummarizer()
    return _summarizer_instance


async def summarize_file_content(text: str, filename: str) -> str:
    """íŒŒì¼ ë‚´ìš©ì„ ì²­í‚¹ ê¸°ë°˜ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    summarizer = await get_file_summarizer()
    return await summarizer.summarize_for_presentation(text, filename)
